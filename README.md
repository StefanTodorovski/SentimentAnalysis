# SentimentAnalysisSentiment Analysis with Severity Labeling on
#LongCovid tweet
 

Линк до видео: https://www.youtube.com/watch?v=KBEbkLH6Lq4

Abstract. Околу 10% до 20% од пациентите имаат Долг Ковид по 
завршување на нивното лечење од Ковид-19. Голем број од нив ги 
искажуваат своите искушенија со вирусот и патот до нивното 
закрепнување на социјалните мрежи како што се Фејсбук , Инстаграм , 
Твитер итн. Социјалните мрежи се најголем извор на податоци , кои 
можеме да ги искористиме за да ги извлечеме потребните информации кои
што ни се потребни за да заклучиме како луѓето се чувствувале по Долг 
Ковид , каде што потоа со користење на техники за обработка на овие 
податоци, со комбинација на “text mining “ , “natural language processing “ и
„machine learning” можеме да креираме апликација која може да анализира
text sentiment.

1.Вовед
Веќе сме запознаени со тоа дека податоците се насекаде околу нас. Тие се 
создаваат во секој момент од вас и од мене и значи дека има онолку 
податоци колу што е можно да се искористат. Каква врска имаат 
податоците со текстот? Во сите негови различни форми текстот всушност 
претставува огромен дел од достапните податоци , околу 80%. Јас и вие 
споделуваме на социјални медиуми , компаниите ги споделуваат своите 
финансиски извештаи , медиумите своите најнови вести , авторите своите 
книги , нашиот универзитет своите курсвеи онлајн , единственото што 
треба да се издвои е дека тоа е богатство на информации и дека е поважно 
од било кога. 

2.Sentiment Analysis in short
Аналиизата на чувствата се користи за да се изведе сентимент од текст со 
користење на техники за рударство на текст и НЛП. На пример да земеме 
трговци на нафта кои го следат пазарот на нафта. Тие во основа имаат два 
вида податоци за да ги донесат нивните одлуки. Имаат структурирани 
податоци како залихи на нафта или показатели за економски раст, но имаат 
и многу неструктурирани податоци на располагање. Тоа се вести кои што 
се ажурираат секојдевно.Тие можат да ги читаат сите вести една по една, 
но веројатно ќе помине целиот ден правејќи го тоа. Нивната цел е да го 
разберат чувството односно дали е позитивно или негативно, со што ќе 
можат да донесат подобри одлуки, тоа е токму нешто каде што можад та 
искористат рударство на текст и нлп. Значи анализата на чувствата има за 
цел да го открие сентиментот во текстот.
3. Анализа на сентимент на LongCovid твитови
 Normalization Vectorization
3.1 Датасет за LongCovid твитови
За овој проект избрав датасет од твитови кои имаат во себе хаштаг 
#LongCovid на едната страна и модел на чувства на другата страна.
Твитотиве всушност нудат многу разновиден и сложен опсег на текстуални
податоци. Корисниците пишуваат како што мислад во моментот на 
пишувањето.
Tweet_text Normalized_tweet Vector Sentiment model
1.Во овој проект искористивме датасет од 110 544 редици , кој содржи три 
колони. User, tweet_text , sentiment. Колоната сентимент содржи три 
вредности : sadness , anger и neutral. 
2. Следно нешто што треба да провериме е дали датасетот е добро 
избалансиран. Може да заклучиме дека датасетот е добро балансиран со 
што можеме да продолжиме со визуелизација на датасетот.
3.2 Визуелизација 
Го искористив pyplot кој помага да се разбере и претстави како твитовите 
се дистрибуираат преку базата на податоците и Wordclouds пакетот за 
зборови кои најчесто се споменати во зависност од сентиментот.
Графичкото претставување може да биде доста информативно. Датасетот е 
прилично добро избалансиран. Според филтрирање може да видиме кои зборови 
се најчесто користени во зависност од тоа дали сентиментот е „anger” , “sadness” 
или пак „neutral”. На сликата е претставено филтрирање според „anger” .Истото 
претставување може да се направи и за другите твитови.
4 Нормализација
Нема навистина правописно правило или граматика при пишување на твитови. 
Само зборови , УРЛ адреси , емотикони и нешто за споделување се дел од 
работите кои го прават текстот интересен. Може да видиме дека голем број 
твитови можат да бидат неуредни , затоа е потребно да се исчистат твитовите и 
нормализираат. Ако сакаме машините да научат и да го препознаат чувтството на 
таквите реченици, можеме да им олесниме со обезбедување чисти и 
нормализирани речиници. Искроситив различни фунцкии за чистење на твитот 
како што се replace_user , demojize , replace_url , replace_hashtag , to_lowercase , 
punct_repetition , fix_contractions , tokenization , stemming. Во продолжение ќе 
дадам објаснување за секоја од функциите.
4.1 Чистење на твитот
-Фунцкијата replace_user има улога да ги замени сите имиња на корисници,
така што после секој знак ‘@’ што го означува корисникот на твитер ќе го 
замени со ‘twitteruser’ , со што ја олеснуваме работата на машината.
Од пакетоти emoji ја искористивме функцијата demojize која ги заменува 
сите emoji со текст разбирлив за машината. 
Промена на секое УРЛ со празен стринг.
До сега ги исчистивме твитовите со нивните специфични елементи со 
користење на регекс , како промена на корисник , урл , емотикони , хаштаг 
и слично. Но, постојат и други елементи за чистење на твитот на пример 
еден збор со една буква на крај или повеќе развлечени компјутерот ќе ги 
смета различно . Нешто напишано со голема буква или мала е различно за 
компјутерот па за таа цел подобро е да ги направиме сите мали букви. 
Следно нешто е контракција , за нас е доста разбирливо затоа што го 
знаемо јазикот , но на компјутерот му ја отежнува работата. Затоа 
искориситвме пакет contractions и функција fix_contractions да ја олесниме 
работата на компјутерот и со тоа да го подобриме нашиот модел. Исто така
и повтотрањето на интерпукциските знаци има различно значење кај 
компјутерот па затоа ја искористивме функцијата punct_repetittion која 
сведува на еден знак. 
Да го земеме за пример овој твит , за сега е неисчистен и не многу 
разбирлив за компјутерот. 
По искористување на горенаведените функции за чистење односно 
нормализација на твитот , го добиваме следниот твит , за нас не прави 
многу разлика , но ова на компјутерот му значи многу. Во продолжение ќе 
објаснам кои техники ги искористив за обработка на текст. 
4.2 Обработка на текст
-Tokenization
Едноставно токенизација значи делење на текст на помали парчиња, кои 
потоа компјутерите можат да ги користат за учење.Токенизација исто така 
претставува клучен чекор кон претставување на зоборови преку 
векторизација. Токенизација покрај тоа што претставува делење на 
реченици на зборови , ни нуди можност да избереме зборови што сакаме да
ги зачуваме , а да ги отстраниме тие што не сакаме. 
Tokenization exceptions
 
Постои специфичен пакет кој што може да ни помогне да се справиме со 
интерпкуциските знаци тоа е String пакетот кој го искористив во овој 
проект. Може да се користи за печатење на повечето постоечки 
интерпукциски знаци , во случај ако имаме одлучено дека сакаме да ги 
сочуваме . Исто така искористив и список со сите стоп зборови на одреден 
јазик во овој случај Англискиот. Сите овои стоп зборови ги преземав од 
модулот Stopword. 
Во овој проект одлучив да направам своја фунцкија за токенизација 
наместо да искористам веќе готови како на пример BertTokenizer. Затоа што
при користење на custom_tokenization сами може да ги поставуваме 
правилата и да одлучиме кои зборови да ги задржиме и како да бидат 
изградени токените. 
Оваа Функција зема твит како влез заедно со различни параметри , за 
возврат имаме прилагодена листа на токени. Првото нешто што го правиме
го делиме твитот на посебни токени , со користење на функцијата 
word_tokenize и ни враќа список на токени. Следно нешто што се одлучува 
е кои токени сакаме да ги задржиме а кои не. Во функцијата имаме ставено
keep_punct False што значи не сакаме да ги зачуваме интерпукциските 
знаци .Следно нешто со кое се справуваме се алфа нумеричките знаци , 
односно букви и бројки. Стандарниот параметар е ставен на неточно што 
значи сакаме да задржиме само алфа знаци. На крај се справуваме со 
stopwords. Целта на функцијата е да презема еден ред од твит , го дели на 
токени и ги филтрира овие токени врз основа на параметрите кои ги ние 
доделуваме во функцијата.
- Stemming
Сега кога имаме зборови а не реченици може да направиме дополнителна 
нормализација на зборовите. Постојат неколку методи како што се 
Stemming и Lematization. Во овој проект искористив Stemming затоа што 
користам прилично голем датасет во кој има споменато голем број 
различни зборови , па во случај кога би сакал да искористам Lematization 
треба за секој збор да се направи рачно како би бил скратен и би одземало 
доста време и покрај тоа што со Lematization зборовите имаат поголемо 
значење односно имаат контекст , додека тоа се губи при stemming.
Stemming користиме за да се редуцираат идентични зборови на иста 
основна форма наречена стебло.
Јас искористив snowballStemmer со параметар за англиски јазик , тој е како 
подобрена верзија на Porterstemmer. 
-Vectorization
Ја воведовме библиотеката Scikit Learn која содржи различни 
класификациски регресии и групирачки алгоритми. Исто така обезбедува 
многу корисни алатки за претпроцесирање. Направив измена на првичниот
датасет , така што додадов нова коломна која содржи токенизирана верзија 
на твитот и додадов колона која го содржи сентиментот во бинарен формат 
( 0 ,1 ,2 ).
Следен чекор е да се конверира во листа. Креирав две листи една X за 
токените и друга Y за сентиментот односно чувството.
-Bag of Words 
Постојат повеќе методи за векторизатија на твитови. Како што се Bag of 
Words , Positive/negative frequencies , TF-IDF итн. Јас во овој проект 
искористив Bag of Words. Идејата на овој метод односно вреќа со зборови е
да ги собере сите зборови во еден ентитет односно да се погледне првиот 
збор во матрицата и да се провери колку пати тој се појавува во соодветен 
твит.
Го импортираме CountVectorizer кој е всушност ист како вреќа со зборови 
(Bag of Words). Функцијата всушност зема корпус на твит како влез , на 
параметрите користиме ламбда со што сакаме да постигнеме да не ги 
користиме способностите за учење на sckit learn , туку да го заобиколиме 
овој чекор затоа што веќе имаме предпроцесирана реченица.
4.3 Sentiment Analysis
За да можеме да го одредиме сентиментот до сега поминавме низ три 
фази , тоа беа чистење односно нормализација на твитот , токенизација и 
векторизација. 
Со завршени три фази можеме да направиме проверка да видиме дека се е 
како што треба во градење на моделот. Датасетот го делиме за тестирање и 
тренирање. Оваа функција го дели на 4 различни променливи . Користиме 
85% за обука и 20% за тестирање , но се зависи од големина на нашата база
на податоци. Доколку имаме милиони податоци би било подобро да го 
зголемиме процентот на обука.
Го искористив моделот на логистичка регресија да предвидување затоа што
направив споредба со други алгоритми како што се NaiveBayes , невронски
мрежи , SVM и добив најдобри резултати со користење на овој метод . 
Логистичка регресија без дополнителни параметри дава бинарен излез , 
односно се користи за предикција на сентимент кој има две вредности (пр. 
Позитивно , негативно) , затоа додадовме параметар multi_class = ovr , кој 
користи ovr стратегија односно one vs rest. 
4.4 Performance Measures
Може да видиме дека со користење на Логистичка регресија и 
CountVectorizer добивме 74.09% точност. Не значи дека ова се единствени 
или најдобрите методи , но се доволно точни за типот на апликацијата што 
требаше да се развие.
5. Заклучок 
Поминавме низ различни чекори за да го предвидиме чувството на дел од 
текстот односно во овој случај на твитови кои содржат хаштаг LongCovid. 
Датасетот е исчистен и може да се тестира со вистиснки и непознати 
твитови. Јас испробав повеќе примери кои првин треба да ги обработиме 
користејќи ги нашите функции за обработка на твит , потоа треба да го 
трансформираме во вектор со користејќи ја нашата функција 
CountVectorizer и на крај го користиме нашиот обучен логистички 
регресивен модел за multi_class , и можеме да предвидуваме твитови. 
Референци:
[1] Kaggle https://www.kaggle.com/datasets/matt0922/twitter-long-covid-2023
[2] Sentiment Analysis Using Python 
https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-anlp-use-case-for-beginners/
[3] Twitter Developer Platform 
https://developer.twitter.com/en/docs/tutorials/how-to-analyze-the-sentiment-ofyour-own-tweets
[4] Neethu M,S and Rajashree R,” Sentiment Analysis in Twitter using Machine 
Learning Techniques” 4th ICCCNT 2013,at Tiruchengode, India. IEEE – 31661 
[5] V. M. K. Peddinti and P. Chintalapoodi, “Domain adaptation in sentiment 
analysis of twitter,” in Analyzing Microtext Workshop, AAAI, 2011. 
